{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHwCm4G1eTFF"
      },
      "outputs": [],
      "source": [
        "!pip install openai langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnHh4fXFh069"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Va4tk6yNd55U"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import langchain\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_33n6GsVfZeZ",
        "outputId": "b9b526ec-e4c6-400d-adec-4c92bf5b27d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/290.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/290.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.11.0)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-4.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dy14htHplIS9",
        "outputId": "a63f6774-d7f1-48ad-d1ec-d67d6f4ed865"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTuojjK4AR_d"
      },
      "source": [
        "Extracting OpenAI api key from my google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZf167aXmBZl"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/My Drive/openai_api_key.txt', 'r') as file:\n",
        "    apikey = file.readline().strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4hcoOpdnwVO"
      },
      "outputs": [],
      "source": [
        "!pip install pinecone-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PofGitRvBRKi"
      },
      "source": [
        "We are using OpenAI Embeddings for converting out input text into embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJoPSiF4BAxz",
        "outputId": "e062dd78-b84d-455c-c6f4-d079ef9f32b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x7c1e8c1dff70>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x7c1e7ff5c340>, model='text-embedding-ada-002', dimensions=None, deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "embeddings=OpenAIEmbeddings(api_key=apikey)\n",
        "embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38aGlF3w_0bT"
      },
      "source": [
        "We are using pre-embedding dataset of langchain docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "C56Cu1KV0lcs",
        "outputId": "4926fd3d-096a-434b-a5f9-0d93fc128865"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "repr_error": "Out of range float values are not JSON compliant: nan",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-bf3c1951-0e08-4e33-8cef-1026cf89059f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>values</th>\n",
              "      <th>sparse_values</th>\n",
              "      <th>metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>417ede5d-39be-498f-b518-f47ed4e53b90</td>\n",
              "      <td>[0.005949743557721376, 0.01983247883617878, -0...</td>\n",
              "      <td>None</td>\n",
              "      <td>{'chunk': 0, 'text': '.rst\n",
              ".pdf\n",
              "Welcome to Lan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>110f550d-110b-4378-b95e-141397fa21bc</td>\n",
              "      <td>[0.009401749819517136, 0.02443608082830906, 0....</td>\n",
              "      <td>None</td>\n",
              "      <td>{'chunk': 1, 'text': 'Use Cases#\n",
              "Best practice...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>d5f00f02-3295-4567-b297-5e3262dc2728</td>\n",
              "      <td>[-0.005517194513231516, 0.0208403542637825, 0....</td>\n",
              "      <td>None</td>\n",
              "      <td>{'chunk': 2, 'text': 'Gallery: A collection of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>0b6fe3c6-1f0e-4608-a950-43231e46b08a</td>\n",
              "      <td>[-0.006499645300209522, 0.0011573900701478124,...</td>\n",
              "      <td>None</td>\n",
              "      <td>{'chunk': 0, 'text': 'Search\n",
              "Error\n",
              "Please acti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>39d5f15f-b973-42c0-8c9b-a2df49b627dc</td>\n",
              "      <td>[-0.005658374633640051, 0.00817849114537239, 0...</td>\n",
              "      <td>None</td>\n",
              "      <td>{'chunk': 0, 'text': '.md\n",
              ".pdf\n",
              "Dependents\n",
              "Depe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf3c1951-0e08-4e33-8cef-1026cf89059f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bf3c1951-0e08-4e33-8cef-1026cf89059f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bf3c1951-0e08-4e33-8cef-1026cf89059f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-96039562-f960-46dd-897c-bc592906590b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-96039562-f960-46dd-897c-bc592906590b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-96039562-f960-46dd-897c-bc592906590b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                       id  \\\n",
              "0.0  417ede5d-39be-498f-b518-f47ed4e53b90   \n",
              "1.0  110f550d-110b-4378-b95e-141397fa21bc   \n",
              "2.0  d5f00f02-3295-4567-b297-5e3262dc2728   \n",
              "3.0  0b6fe3c6-1f0e-4608-a950-43231e46b08a   \n",
              "4.0  39d5f15f-b973-42c0-8c9b-a2df49b627dc   \n",
              "\n",
              "                                                values sparse_values  \\\n",
              "0.0  [0.005949743557721376, 0.01983247883617878, -0...          None   \n",
              "1.0  [0.009401749819517136, 0.02443608082830906, 0....          None   \n",
              "2.0  [-0.005517194513231516, 0.0208403542637825, 0....          None   \n",
              "3.0  [-0.006499645300209522, 0.0011573900701478124,...          None   \n",
              "4.0  [-0.005658374633640051, 0.00817849114537239, 0...          None   \n",
              "\n",
              "                                              metadata  \n",
              "0.0  {'chunk': 0, 'text': '.rst\n",
              ".pdf\n",
              "Welcome to Lan...  \n",
              "1.0  {'chunk': 1, 'text': 'Use Cases#\n",
              "Best practice...  \n",
              "2.0  {'chunk': 2, 'text': 'Gallery: A collection of...  \n",
              "3.0  {'chunk': 0, 'text': 'Search\n",
              "Error\n",
              "Please acti...  \n",
              "4.0  {'chunk': 0, 'text': '.md\n",
              ".pdf\n",
              "Dependents\n",
              "Depe...  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pinecone_datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('langchain-python-docs-text-embedding-ada-002')\n",
        "# we drop sparse_values as they are not needed for this example\n",
        "dataset.documents.drop(['metadata'], axis=1, inplace=True)\n",
        "dataset.documents.rename(columns={'blob': 'metadata'}, inplace=True)\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QfbymbUAngk"
      },
      "source": [
        "Initialization of Pinecone and inserting the values into the vector database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mkNCQVZiADc"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone\n",
        "\n",
        "pc = Pinecone(api_key=\"cde0cc99-ae70-404d-bca8-63f3d8057d99\")\n",
        "index = pc.Index(\"congressmanifesto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFXMyaKtp05J",
        "outputId": "54ae6e7d-e7c8-420e-8553-2406d7b349bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {},\n",
              " 'total_vector_count': 0}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03t_uGKS09sK"
      },
      "outputs": [],
      "source": [
        "for batch in dataset.iter_documents(batch_size=100):\n",
        "    index.upsert(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW_Avxcw2bsq",
        "outputId": "c3fa9e8b-e044-47a3-cf3f-4b833c92da9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'': {'vector_count': 3476}},\n",
              " 'total_vector_count': 3476}"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBvVryDUsTVW"
      },
      "outputs": [],
      "source": [
        "!pip install pinecone_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KykVmGMcq4Y1"
      },
      "outputs": [],
      "source": [
        "query = \"how to use pinecone in langchain?\"\n",
        "\n",
        "\n",
        "# retrieve from Pinecone\n",
        "xq = embeddings.embed_query(query)\n",
        "\n",
        "# get relevant contexts (including the questions)\n",
        "res = index.query(vector=xq, top_k=5, include_metadata=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD9GjRY53Vd-",
        "outputId": "3902cd6e-df3c-44e8-f0c2-5b4349716136"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'matches': [{'id': '31882455-5eb6-42a4-bdf0-98ab8a7ca259',\n",
              "              'metadata': {'chunk': 8.0,\n",
              "                           'text': 'LangChain is a framework for including AI '\n",
              "                                   'from large language models inside data '\n",
              "                                   'pipelines and applications. This tutorial '\n",
              "                                   'provides an overview of what you ... '\n",
              "                                   'LangChain is an intuitive framework '\n",
              "                                   'created to assist in developing '\n",
              "                                   'applications driven by a language model, '\n",
              "                                   'such as OpenAI or Hugging Face. This '\n",
              "                                   'documentation covers the steps to '\n",
              "                                   'integrate Pinecone, a high-performance '\n",
              "                                   'vector database, with LangChain, a '\n",
              "                                   'framework for building applications '\n",
              "                                   'powered ... The ability to connect to any '\n",
              "                                   'model, ingest any custom database, and '\n",
              "                                   'build upon a framework that can take '\n",
              "                                   'action provides numerous use cases for ... '\n",
              "                                   'With LangChain, developers can use a '\n",
              "                                   'framework that abstracts the core building '\n",
              "                                   'blocks of LLM applications. LangChain '\n",
              "                                   'empowers developers to ... Build a '\n",
              "                                   'question-answering tool based on financial '\n",
              "                                   \"data with LangChain & Deep Lake's unified \"\n",
              "                                   '& streamable data store. Browse '\n",
              "                                   'applications built on LangChain '\n",
              "                                   'technology. Explore PoC and MVP '\n",
              "                                   'applications created by our community and '\n",
              "                                   'discover innovative use cases for '\n",
              "                                   'LangChain ... LangChain is a great '\n",
              "                                   'framework that can be used for developing '\n",
              "                                   'applications powered by LLMs. When you '\n",
              "                                   'intend to enhance your application ... In '\n",
              "                                   \"this blog, we'll introduce you to \"\n",
              "                                   'LangChain and Ray Serve and how to use '\n",
              "                                   'them to build a search engine using LLM '\n",
              "                                   'embeddings and a vector ... The LinkChain '\n",
              "                                   'Framework simplifies embedding creation '\n",
              "                                   'and storage using Pinecone and Chroma, '\n",
              "                                   'with code that loads files, splits '\n",
              "                                   'documents, and creates embedding ... '\n",
              "                                   'Missing: technology | Must '\n",
              "                                   'include:technology.',\n",
              "                           'url': 'https://python.langchain.com/en/latest/modules/chains/examples/flare.html'},\n",
              "              'score': 0.854089379,\n",
              "              'values': []},\n",
              "             {'id': '4eaeac1a-642f-472a-9851-5bc7886876a0',\n",
              "              'metadata': {'chunk': 0.0,\n",
              "                           'text': '.md\\n'\n",
              "                                   '.pdf\\n'\n",
              "                                   'Pinecone\\n'\n",
              "                                   ' Contents \\n'\n",
              "                                   'Installation and Setup\\n'\n",
              "                                   'Wrappers\\n'\n",
              "                                   'VectorStore\\n'\n",
              "                                   'Pinecone#\\n'\n",
              "                                   'This page covers how to use the Pinecone '\n",
              "                                   'ecosystem within LangChain.\\n'\n",
              "                                   'It is broken into two parts: installation '\n",
              "                                   'and setup, and then references to specific '\n",
              "                                   'Pinecone wrappers.\\n'\n",
              "                                   'Installation and Setup#\\n'\n",
              "                                   'Install the Python SDK with pip install '\n",
              "                                   'pinecone-client\\n'\n",
              "                                   'Wrappers#\\n'\n",
              "                                   'VectorStore#\\n'\n",
              "                                   'There exists a wrapper around Pinecone '\n",
              "                                   'indexes, allowing you to use it as a '\n",
              "                                   'vectorstore,\\n'\n",
              "                                   'whether for semantic search or example '\n",
              "                                   'selection.\\n'\n",
              "                                   'To import this vectorstore:\\n'\n",
              "                                   'from langchain.vectorstores import '\n",
              "                                   'Pinecone\\n'\n",
              "                                   'For a more detailed walkthrough of the '\n",
              "                                   'Pinecone wrapper, see this notebook\\n'\n",
              "                                   'previous\\n'\n",
              "                                   'PGVector\\n'\n",
              "                                   'next\\n'\n",
              "                                   'PipelineAI\\n'\n",
              "                                   ' Contents\\n'\n",
              "                                   '  \\n'\n",
              "                                   'Installation and Setup\\n'\n",
              "                                   'Wrappers\\n'\n",
              "                                   'VectorStore\\n'\n",
              "                                   'By Harrison Chase\\n'\n",
              "                                   '    \\n'\n",
              "                                   '      © Copyright 2023, Harrison Chase.\\n'\n",
              "                                   '      \\n'\n",
              "                                   '  Last updated on May 30, 2023.',\n",
              "                           'url': 'https://python.langchain.com/en/latest/integrations/pinecone.html'},\n",
              "              'score': 0.82247442,\n",
              "              'values': []},\n",
              "             {'id': '2f66a6a5-c829-4118-acb8-f08667f3f95d',\n",
              "              'metadata': {'chunk': 2.0,\n",
              "                           'text': 'for full documentation on:\\\\n\\\\nGetting '\n",
              "                                   'started (installation, setting up the '\n",
              "                                   'environment, simple examples)\\\\n\\\\nHow-To '\n",
              "                                   'examples (demos, integrations, helper '\n",
              "                                   'functions)\\\\n\\\\nReference (full API '\n",
              "                                   'docs)\\\\n\\\\nResources (high-level '\n",
              "                                   'explanation of core '\n",
              "                                   'concepts)\\\\n\\\\nð\\\\x9f\\\\x9a\\\\x80 What can '\n",
              "                                   'this help with?\\\\n\\\\nThere are six main '\n",
              "                                   'areas that LangChain is designed to help '\n",
              "                                   'with.\\\\nThese are, in increasing order of '\n",
              "                                   'complexity:\\\\n\\\\nð\\\\x9f“\\\\x83 LLMs and '\n",
              "                                   'Prompts:\\\\n\\\\nThis includes prompt '\n",
              "                                   'management, prompt optimization, a generic '\n",
              "                                   'interface for all LLMs, and common '\n",
              "                                   'utilities for working with '\n",
              "                                   'LLMs.\\\\n\\\\nð\\\\x9f”\\\\x97 '\n",
              "                                   'Chains:\\\\n\\\\nChains go beyond a single LLM '\n",
              "                                   'call and involve sequences of calls '\n",
              "                                   '(whether to an LLM or a different '\n",
              "                                   'utility). LangChain provides a standard '\n",
              "                                   'interface for chains, lots of integrations '\n",
              "                                   'with other tools, and end-to-end chains '\n",
              "                                   'for common applications.\\\\n\\\\nð\\\\x9f“\\\\x9a '\n",
              "                                   'Data Augmented Generation:\\\\n\\\\nData '\n",
              "                                   'Augmented Generation involves specific '\n",
              "                                   'types of chains that first interact with '\n",
              "                                   'an external data source to fetch data for '\n",
              "                                   'use in the generation step. Examples '\n",
              "                                   'include summarization of long pieces of '\n",
              "                                   'text and question/answering over specific '\n",
              "                                   'data sources.\\\\n\\\\nð\\\\x9f¤\\\\x96 '\n",
              "                                   'Agents:\\\\n\\\\nAgents involve an LLM making '\n",
              "                                   'decisions about which Actions to take, '\n",
              "                                   'taking that Action, seeing an Observation, '\n",
              "                                   'and repeating that until done. LangChain',\n",
              "                           'url': 'https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/markdown.html'},\n",
              "              'score': 0.795799792,\n",
              "              'values': []},\n",
              "             {'id': 'ef0c5fb3-961a-4ede-88d1-d522fb5723ee',\n",
              "              'metadata': {'chunk': 10.0,\n",
              "                           'text': 'LangChain is an intuitive framework '\n",
              "                                   'created to assist in developing '\n",
              "                                   'applications driven by a language model, '\n",
              "                                   'such as OpenAI or Hugging Face. Missing: '\n",
              "                                   'decentralized | Must '\n",
              "                                   'include:decentralized. LangChain, created '\n",
              "                                   'by Harrison Chase, is a Python library '\n",
              "                                   'that provides out-of-the-box support to '\n",
              "                                   'build NLP applications using LLMs. '\n",
              "                                   'Missing: decentralized | Must '\n",
              "                                   'include:decentralized. LangChain provides '\n",
              "                                   'a standard interface for chains, enabling '\n",
              "                                   'developers to create sequences of calls '\n",
              "                                   'that go beyond a single LLM call. Chains '\n",
              "                                   '... Missing: decentralized platform '\n",
              "                                   'natural. LangChain is a powerful framework '\n",
              "                                   'that simplifies the process of building '\n",
              "                                   'advanced language model applications. '\n",
              "                                   'Missing: platform | Must include:platform. '\n",
              "                                   'Are your language models ignoring previous '\n",
              "                                   'instructions ... Duration: 32:23. Posted: '\n",
              "                                   'Feb 21, 2023. LangChain is a framework '\n",
              "                                   'that enables quick and easy development of '\n",
              "                                   'applications ... Prompting is the new way '\n",
              "                                   'of programming NLP models. Missing: '\n",
              "                                   'decentralized platform. It then uses '\n",
              "                                   'natural language processing and machine '\n",
              "                                   'learning algorithms to search ... '\n",
              "                                   'Summarization is handled via cohere, QnA '\n",
              "                                   'is handled via langchain, ... LangChain is '\n",
              "                                   'a framework for developing applications '\n",
              "                                   'powered by language models. ... There are '\n",
              "                                   'several main modules that LangChain '\n",
              "                                   'provides support for. Missing: '\n",
              "                                   'decentralized platform. In the '\n",
              "                                   'healthcare-chain system, blockchain '\n",
              "                                   'provides an appreciated secure ... The '\n",
              "                                   'entire process of adding new and previous '\n",
              "                                   'block data is performed based on ... '\n",
              "                                   'ChatGPT is a large language model '\n",
              "                                   'developed by OpenAI, ... tool for a wide '\n",
              "                                   'range of applications, including natural '\n",
              "                                   'language processing, ...',\n",
              "                           'url': 'https://python.langchain.com/en/latest/modules/chains/examples/flare.html'},\n",
              "              'score': 0.793520093,\n",
              "              'values': []},\n",
              "             {'id': 'e26407fd-df5d-4e88-a59e-2ffd2b2b87d6',\n",
              "              'metadata': {'chunk': 17.0,\n",
              "                           'text': 'an Observation, and repeating that until '\n",
              "                                   'done. LangChain provides a standard '\n",
              "                                   'interface for agents, a selection of '\n",
              "                                   'agents to choose from, and examples of end '\n",
              "                                   'to end agents.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nUse '\n",
              "                                   'Cases#\\\\nThe above modules can be used in '\n",
              "                                   'a variety of ways. LangChain also provides '\n",
              "                                   'guidance and assistance in this. Below are '\n",
              "                                   'some of the common use cases LangChain '\n",
              "                                   'supports.\\\\n\\\\nPersonal Assistants: The '\n",
              "                                   'main LangChain use case. Personal '\n",
              "                                   'assistants need to take actions, remember '\n",
              "                                   'interactions, and have knowledge about '\n",
              "                                   'your data.\\\\nQuestion Answering: The '\n",
              "                                   'second big LangChain use case. Answering '\n",
              "                                   'questions over specific documents, only '\n",
              "                                   'utilizing the information in those '\n",
              "                                   'documents to construct an '\n",
              "                                   'answer.\\\\nChatbots: Since language models '\n",
              "                                   'are good at producing text, that makes '\n",
              "                                   'them ideal for creating '\n",
              "                                   'chatbots.\\\\nQuerying Tabular Data: If you '\n",
              "                                   'want to understand how to use LLMs to '\n",
              "                                   'query data that is stored in a tabular '\n",
              "                                   'format (csvs, SQL, dataframes, etc) you '\n",
              "                                   'should read this page.\\\\nInteracting with '\n",
              "                                   'APIs: Enabling LLMs to interact with APIs '\n",
              "                                   'is extremely powerful in order to give '\n",
              "                                   'them more up-to-date information and allow '\n",
              "                                   'them to take actions.\\\\nExtraction: '\n",
              "                                   'Extract structured information from '\n",
              "                                   'text.\\\\nSummarization: Summarizing longer '\n",
              "                                   'documents into shorter, more condensed '\n",
              "                                   'chunks of information. A type of Data '\n",
              "                                   'Augmented Generation.\\\\nEvaluation: '\n",
              "                                   'Generative models are notoriously',\n",
              "                           'url': 'https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/sitemap.html'},\n",
              "              'score': 0.792848647,\n",
              "              'values': []}],\n",
              " 'namespace': '',\n",
              " 'usage': {'read_units': 6}}"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeTl2AAm34Nz"
      },
      "outputs": [],
      "source": [
        "# get list of retrieved text\n",
        "contexts = [item['metadata']['text'] for item in res['matches']]\n",
        "\n",
        "augmented_query = \"\\n\\n---\\n\\n\".join(contexts)+\"\\n\\n-----\\n\\n\"+query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DViSs89S4EAx",
        "outputId": "1dbfe890-3bcd-4f96-9b09-2071e5ef5139"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangChain is a framework for including AI from large language models inside data pipelines and applications. This tutorial provides an overview of what you ... LangChain is an intuitive framework created to assist in developing applications driven by a language model, such as OpenAI or Hugging Face. This documentation covers the steps to integrate Pinecone, a high-performance vector database, with LangChain, a framework for building applications powered ... The ability to connect to any model, ingest any custom database, and build upon a framework that can take action provides numerous use cases for ... With LangChain, developers can use a framework that abstracts the core building blocks of LLM applications. LangChain empowers developers to ... Build a question-answering tool based on financial data with LangChain & Deep Lake's unified & streamable data store. Browse applications built on LangChain technology. Explore PoC and MVP applications created by our community and discover innovative use cases for LangChain ... LangChain is a great framework that can be used for developing applications powered by LLMs. When you intend to enhance your application ... In this blog, we'll introduce you to LangChain and Ray Serve and how to use them to build a search engine using LLM embeddings and a vector ... The LinkChain Framework simplifies embedding creation and storage using Pinecone and Chroma, with code that loads files, splits documents, and creates embedding ... Missing: technology | Must include:technology.\n",
            "\n",
            "---\n",
            "\n",
            ".md\n",
            ".pdf\n",
            "Pinecone\n",
            " Contents \n",
            "Installation and Setup\n",
            "Wrappers\n",
            "VectorStore\n",
            "Pinecone#\n",
            "This page covers how to use the Pinecone ecosystem within LangChain.\n",
            "It is broken into two parts: installation and setup, and then references to specific Pinecone wrappers.\n",
            "Installation and Setup#\n",
            "Install the Python SDK with pip install pinecone-client\n",
            "Wrappers#\n",
            "VectorStore#\n",
            "There exists a wrapper around Pinecone indexes, allowing you to use it as a vectorstore,\n",
            "whether for semantic search or example selection.\n",
            "To import this vectorstore:\n",
            "from langchain.vectorstores import Pinecone\n",
            "For a more detailed walkthrough of the Pinecone wrapper, see this notebook\n",
            "previous\n",
            "PGVector\n",
            "next\n",
            "PipelineAI\n",
            " Contents\n",
            "  \n",
            "Installation and Setup\n",
            "Wrappers\n",
            "VectorStore\n",
            "By Harrison Chase\n",
            "    \n",
            "      © Copyright 2023, Harrison Chase.\n",
            "      \n",
            "  Last updated on May 30, 2023.\n",
            "\n",
            "---\n",
            "\n",
            "for full documentation on:\\n\\nGetting started (installation, setting up the environment, simple examples)\\n\\nHow-To examples (demos, integrations, helper functions)\\n\\nReference (full API docs)\\n\\nResources (high-level explanation of core concepts)\\n\\nð\\x9f\\x9a\\x80 What can this help with?\\n\\nThere are six main areas that LangChain is designed to help with.\\nThese are, in increasing order of complexity:\\n\\nð\\x9f“\\x83 LLMs and Prompts:\\n\\nThis includes prompt management, prompt optimization, a generic interface for all LLMs, and common utilities for working with LLMs.\\n\\nð\\x9f”\\x97 Chains:\\n\\nChains go beyond a single LLM call and involve sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications.\\n\\nð\\x9f“\\x9a Data Augmented Generation:\\n\\nData Augmented Generation involves specific types of chains that first interact with an external data source to fetch data for use in the generation step. Examples include summarization of long pieces of text and question/answering over specific data sources.\\n\\nð\\x9f¤\\x96 Agents:\\n\\nAgents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain\n",
            "\n",
            "---\n",
            "\n",
            "LangChain is an intuitive framework created to assist in developing applications driven by a language model, such as OpenAI or Hugging Face. Missing: decentralized | Must include:decentralized. LangChain, created by Harrison Chase, is a Python library that provides out-of-the-box support to build NLP applications using LLMs. Missing: decentralized | Must include:decentralized. LangChain provides a standard interface for chains, enabling developers to create sequences of calls that go beyond a single LLM call. Chains ... Missing: decentralized platform natural. LangChain is a powerful framework that simplifies the process of building advanced language model applications. Missing: platform | Must include:platform. Are your language models ignoring previous instructions ... Duration: 32:23. Posted: Feb 21, 2023. LangChain is a framework that enables quick and easy development of applications ... Prompting is the new way of programming NLP models. Missing: decentralized platform. It then uses natural language processing and machine learning algorithms to search ... Summarization is handled via cohere, QnA is handled via langchain, ... LangChain is a framework for developing applications powered by language models. ... There are several main modules that LangChain provides support for. Missing: decentralized platform. In the healthcare-chain system, blockchain provides an appreciated secure ... The entire process of adding new and previous block data is performed based on ... ChatGPT is a large language model developed by OpenAI, ... tool for a wide range of applications, including natural language processing, ...\n",
            "\n",
            "---\n",
            "\n",
            "an Observation, and repeating that until done. LangChain provides a standard interface for agents, a selection of agents to choose from, and examples of end to end agents.\\n\\n\\n\\n\\n\\nUse Cases#\\nThe above modules can be used in a variety of ways. LangChain also provides guidance and assistance in this. Below are some of the common use cases LangChain supports.\\n\\nPersonal Assistants: The main LangChain use case. Personal assistants need to take actions, remember interactions, and have knowledge about your data.\\nQuestion Answering: The second big LangChain use case. Answering questions over specific documents, only utilizing the information in those documents to construct an answer.\\nChatbots: Since language models are good at producing text, that makes them ideal for creating chatbots.\\nQuerying Tabular Data: If you want to understand how to use LLMs to query data that is stored in a tabular format (csvs, SQL, dataframes, etc) you should read this page.\\nInteracting with APIs: Enabling LLMs to interact with APIs is extremely powerful in order to give them more up-to-date information and allow them to take actions.\\nExtraction: Extract structured information from text.\\nSummarization: Summarizing longer documents into shorter, more condensed chunks of information. A type of Data Augmented Generation.\\nEvaluation: Generative models are notoriously\n",
            "\n",
            "-----\n",
            "\n",
            "how to use pinecone in langchain?\n"
          ]
        }
      ],
      "source": [
        "print(augmented_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90w5Y5uhBpYC"
      },
      "source": [
        "Setting up our Q&A chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sy2h2Zst4ICK"
      },
      "outputs": [],
      "source": [
        "\n",
        "primer = f\"\"\"You are Q&A bot. A highly intelligent system that answers\n",
        "user questions based on the information provided by the user above\n",
        "each question. If the information can not be found in the information\n",
        "provided by the user you truthfully say \"I don't know\".\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "\n",
        "    api_key=apikey,\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": primer},\n",
        "        {\"role\": \"user\", \"content\": augmented_query}\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "VIQWjlTM6oMt",
        "outputId": "0efc6172-f4ab-4ced-e4c1-e7ad0dce9211"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "To use Pinecone in LangChain, you can follow these steps:\n",
              "\n",
              "1. **Installation and Setup**: Install the Python SDK with `pip install pinecone-client`.\n",
              "   \n",
              "2. **Wrappers**: There exists a wrapper around Pinecone indexes, allowing you to use it as a vector store, whether for semantic search or example selection.\n",
              "   \n",
              "    To import this vector store in LangChain, you can use the following code snippet:\n",
              "   \n",
              "    ```python\n",
              "    from langchain.vectorstores import Pinecone\n",
              "    ```\n",
              "\n",
              "For a more detailed walkthrough of using the Pinecone wrapper within LangChain, you can refer to the notebook mentioned in the documentation.\n",
              "\n",
              "If you need further assistance or more information on using Pinecone with LangChain, feel free to ask!"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "display(Markdown(chat_completion.choices[0].message.content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49QTTPb28C53"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
